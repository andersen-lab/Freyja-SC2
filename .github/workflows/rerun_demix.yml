name: Rerun demix
on:
  schedule:
    - cron: '0 0 * * *'

jobs:
  rerun_demix:
    permissions:
        contents: write
        id-token: write

    runs-on: self-hosted

    steps:
      - name: Checkout main
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup nextflow
        uses: nf-core/setup-nextflow@v1
      
      - name: Setup Python
        run: |
              echo ${{secrets.DPILZ_USR_PWD}} | sudo -S dnf install python3 -y
              echo ${{secrets.DPILZ_USR_PWD}} | sudo -S dnf install python3-pip -y
              pip3 install pandas numpy pyyaml ffq epiweeks

      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v2'
        with:
          version: '>= 363.0.0'
          
      - id: 'auth'
        name: 'Authenticate with gcloud'
        uses: 'google-github-actions/auth@v2'
        with:
          workload_identity_provider: 'projects/12767718289/locations/global/workloadIdentityPools/github/providers/freyja-sra'
          service_account: 'outbreak-ww@andersen-lab-primary.iam.gserviceaccount.com'
              
      - name: 'Get samples to re-run'
        run: |
              mkdir demix_rerun
              python scripts/get_samples_for_demix_rerun.py
              bash scripts/get_variants_output.sh
      
      - name: 'Rerun demix'
        run: |
              export NXF_ENABLE_VIRTUAL_THREADS=false
              nextflow run main.nf \
                -entry rerun_demix \
                -profile docker \
                --accession_list data/samples_to_rerun.csv \
                --variants_dir demix_rerun \

      - name: 'Aggregate demix results'
        run: |
              python scripts/aggregate_demix.py

      - name: 'Replace old demix results'
        run: |
              gcloud storage cp gs://outbreak-ww-data/aggregate/aggregate_demix.json outputs/aggregate/aggregate_demix.json
              python scripts/update_aggregate_demix.py
              rm -rf outputs/aggregate/aggregate_demix_new.json

      - name: 'Aggregate demix by week'
        run: |
              python scripts/aggregate_demix_by_week.py

      - name: 'Upload results'
        run: |
              gcloud storage cp -r outputs/aggregate gs://outbreak-ww-data/
              gcloud storage cp -r outputs/demix gs://outbreak-ww-data/


      - name: 'Get updated barcodes and lineages from Freyja repo'
        run: |
              git clone http://github.com/andersen-lab/Freyja
              cp Freyja/freyja/data/usher_barcodes.csv data/
              cp Freyja/freyja/data/lineages.yml data/

      - name: 'Commit updated barcodes and lineages to main repo'
        run: |
              if [[($(git status data/usher_barcodes.csv --porcelain | wc -c) -ne 0)]]; then
                git config --local user.name "$GITHUB_ACTOR"
                git config --local user.email "$GITHUB_ACTOR@users.noreply.github.com"
                git remote set-url origin https://github.com/andersen-lab/Freyja-SRA
                git add data/usher_barcodes.csv
                git add data/lineages.yml
                git commit -m "Update Freyja barcodes"
                git push --force
              fi
      



