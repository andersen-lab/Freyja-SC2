name: Process samples

on:
  schedule:
    #- cron: '0 * * * *'
    - cron: '0 1-17/2 * * *'
env:
  BATCH_SIZE: 50
  

jobs:
  run_samples:
    permissions:
      contents: write
      id-token: write

    runs-on: self-hosted

    steps:
      - name: Checkout main
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup nextflow
        uses: nf-core/setup-nextflow@v1
      
      - name: Install python
        run: |
              dnf install python3 -y
              dnf install python3-pip -y

      - name: Install dependencies
        run: |
              pip3 install pandas numpy

      - name: Run pipeline on new samples
        run: |
              nextflow run main.nf \
                  --accession_list data/samples_to_run.csv \
                  --num_samples $BATCH_SIZE \
                  -profile docker \
                  -with-report report.html \
                  -entry sra &
              BG_PID=$!
              wait $BG_PID

      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v2'
        with:
          version: '>= 363.0.0'
      
      - id: 'auth'
        name: 'Authenticate with gcloud'
        uses: 'google-github-actions/auth@v2'
        with:
          workload_identity_provider: 'projects/12767718289/locations/global/workloadIdentityPools/github/providers/freyja-sra'
          service_account: 'outbreak-ww@andersen-lab-primary.iam.gserviceaccount.com'

          
      - name: Aggregate outputs
        run: |
              python scripts/aggregate_demix.py
              python scripts/aggregate_variants.py
              python scripts/aggregate_metadata.py

      - id: 'download-aggregated-outputs'
        name: 'Download aggregated outputs'
        run: |
              gsutil cp gs://outbreak-ww-data/aggregate/aggregate_demix.json outputs/aggregate_demix.json
              gsutil cp gs://outbreak-ww-data/aggregate/aggregate_variants.json outputs/aggregate_variants.json
              gsutil cp gs://outbreak-ww-data/aggregate/aggregate_metadata.json outputs/aggregate_metadata.json

      - id: 'concatenate-outputs'
        name: 'Concatenate outputs'
        run: |
              python scripts/concat_agg_files.py

      - id: 'upload-outputs'
        name: 'Upload Outputs to Cloud Storage'
        uses: 'google-github-actions/upload-cloud-storage@v2'
        with:
          path: 'outputs/'
          destination: 'outbreak-ww-data/'
          parent: false

      - name: 'Update processed samples'
        run: |
              python scripts/update_sample_status.py $BATCH_SIZE
              sed -i "2,$((BATCH_SIZE+1))d" data/samples_to_run.csv
      
      - name: 'Commit and push changes'
        run: |
              git config --local user.name "$GITHUB_ACTOR"
              git config --local user.email "$GITHUB_ACTOR@users.noreply.github.com"
              git remote set-url origin https://github.com/andersen-lab/Freyja-SRA
              git add data/all_metadata.csv
              git add data/samples_to_run.csv
              git add data/all_metadata.csv
              git add report.html
              git commit -m "Update processed samples"
              git push --force